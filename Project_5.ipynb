{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: 1928\n",
      "df_valid: 643\n",
      "df_test: 643\n"
     ]
    }
   ],
   "source": [
    "df_train, df_other = train_test_split(df, test_size=0.4, random_state=12345)\n",
    "df_valid, df_test = train_test_split(df_other, test_size=0.5, random_state=12345)\n",
    "print('df_train:', len(df_train))\n",
    "print('df_valid:', len(df_valid))\n",
    "print('df_test:', len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Всё разбилось корректно, разбивала по схеме 60,20,20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Исследуйте модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75778</td>\n",
       "      <td>0.754277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.787863</td>\n",
       "      <td>0.782271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.807573</td>\n",
       "      <td>0.785381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.810685</td>\n",
       "      <td>0.77916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.820021</td>\n",
       "      <td>0.77916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.837656</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.855809</td>\n",
       "      <td>0.782271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0.862552</td>\n",
       "      <td>0.77916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>0.881224</td>\n",
       "      <td>0.782271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.889004</td>\n",
       "      <td>0.774495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.906639</td>\n",
       "      <td>0.762053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.762053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>0.941909</td>\n",
       "      <td>0.755832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>0.955394</td>\n",
       "      <td>0.758942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0.967842</td>\n",
       "      <td>0.746501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0.978734</td>\n",
       "      <td>0.734059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>0.98444</td>\n",
       "      <td>0.735614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>0.988589</td>\n",
       "      <td>0.730949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0.989108</td>\n",
       "      <td>0.727838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.993257</td>\n",
       "      <td>0.721617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth accuracy_train accuracy_valid\n",
       "0      1        0.75778       0.754277\n",
       "1      2       0.787863       0.782271\n",
       "2      3       0.807573       0.785381\n",
       "3      4       0.810685        0.77916\n",
       "4      5       0.820021        0.77916\n",
       "5      6       0.837656       0.783826\n",
       "6      7       0.855809       0.782271\n",
       "7      8       0.862552        0.77916\n",
       "8      9       0.881224       0.782271\n",
       "9     10       0.889004       0.774495\n",
       "10    11       0.906639       0.762053\n",
       "11    12       0.925311       0.762053\n",
       "12    13       0.941909       0.755832\n",
       "13    14       0.955394       0.758942\n",
       "14    15       0.967842       0.746501\n",
       "15    16       0.978734       0.734059\n",
       "16    17        0.98444       0.735614\n",
       "17    18       0.988589       0.730949\n",
       "18    19       0.989108       0.727838\n",
       "19    20       0.993257       0.721617"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#задаём features и target\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']\n",
    "\n",
    "#исследуем дерево\n",
    "tree_result = pd.DataFrame(columns = ['depth', 'accuracy_train', 'accuracy_valid'])\n",
    "i= 0\n",
    "for depth in range(1, 21, 1):\n",
    "    model_tree = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    predictions_tree_train = model_tree.predict(features_train)\n",
    "    predictions_tree_valid = model_tree.predict(features_valid)\n",
    "    accuracy_tree_train = accuracy_score(target_train, predictions_tree_train)\n",
    "    accuracy_tree_valid = accuracy_score(target_valid, predictions_tree_valid)\n",
    "    tree_result.loc[i, 'depth'] = depth\n",
    "    tree_result.loc[i, 'accuracy_train'] = accuracy_tree_train\n",
    "    tree_result.loc[i, 'accuracy_valid'] = accuracy_tree_valid\n",
    "    i +=1\n",
    "    \n",
    "tree_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estim</th>\n",
       "      <th>depth</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.760373</td>\n",
       "      <td>0.769829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.817427</td>\n",
       "      <td>0.785381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.835581</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.866183</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.880705</td>\n",
       "      <td>0.780715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.778527</td>\n",
       "      <td>0.777605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814315</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.835062</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.869813</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.885892</td>\n",
       "      <td>0.791602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814315</td>\n",
       "      <td>0.788491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>0.870851</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.892116</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.812241</td>\n",
       "      <td>0.788491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.797823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.791602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814834</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841805</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>0.873444</td>\n",
       "      <td>0.797823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0.895747</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.815871</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.840768</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.872925</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.893672</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>0.815871</td>\n",
       "      <td>0.788491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>0.89471</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>0.785381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>0.816909</td>\n",
       "      <td>0.790047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "      <td>0.84388</td>\n",
       "      <td>0.802488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.808709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>0.89471</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.785381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.815871</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>6</td>\n",
       "      <td>0.841286</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>0.873963</td>\n",
       "      <td>0.807154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>0.894191</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789419</td>\n",
       "      <td>0.783826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>0.815871</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>0.840249</td>\n",
       "      <td>0.799378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.807154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.893154</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estim depth accuracy_train accuracy_valid\n",
       "0      5     2       0.760373       0.769829\n",
       "1      5     4       0.817427       0.785381\n",
       "2      5     6       0.835581       0.794712\n",
       "3      5     8       0.866183       0.793157\n",
       "4      5    10       0.880705       0.780715\n",
       "5     10     2       0.778527       0.777605\n",
       "6     10     4       0.814315       0.790047\n",
       "7     10     6       0.835062       0.800933\n",
       "8     10     8       0.869813       0.796267\n",
       "9     10    10       0.885892       0.791602\n",
       "10    15     2       0.788382       0.783826\n",
       "11    15     4       0.814315       0.788491\n",
       "12    15     6         0.8361       0.800933\n",
       "13    15     8       0.870851       0.794712\n",
       "14    15    10       0.892116       0.786936\n",
       "15    20     2       0.788382       0.783826\n",
       "16    20     4       0.812241       0.788491\n",
       "17    20     6       0.842324       0.799378\n",
       "18    20     8       0.871369       0.797823\n",
       "19    20    10       0.894191       0.791602\n",
       "20    25     2         0.7889       0.786936\n",
       "21    25     4       0.814834       0.790047\n",
       "22    25     6       0.841805       0.799378\n",
       "23    25     8       0.873444       0.797823\n",
       "24    25    10       0.895747       0.796267\n",
       "25    30     2         0.7889       0.783826\n",
       "26    30     4       0.815871       0.786936\n",
       "27    30     6       0.840768       0.800933\n",
       "28    30     8       0.872925       0.799378\n",
       "29    30    10       0.893672       0.794712\n",
       "30    35     2       0.788382       0.783826\n",
       "31    35     4       0.815871       0.788491\n",
       "32    35     6       0.842324       0.799378\n",
       "33    35     8       0.875519       0.794712\n",
       "34    35    10        0.89471       0.793157\n",
       "35    40     2         0.7889       0.785381\n",
       "36    40     4       0.816909       0.790047\n",
       "37    40     6        0.84388       0.802488\n",
       "38    40     8          0.875       0.808709\n",
       "39    40    10        0.89471       0.796267\n",
       "40    45     2       0.788382       0.785381\n",
       "41    45     4       0.815871       0.786936\n",
       "42    45     6       0.841286       0.799378\n",
       "43    45     8       0.873963       0.807154\n",
       "44    45    10       0.894191       0.793157\n",
       "45    50     2       0.789419       0.783826\n",
       "46    50     4       0.815871       0.786936\n",
       "47    50     6       0.840249       0.799378\n",
       "48    50     8       0.875519       0.807154\n",
       "49    50    10       0.893154       0.793157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#исследуем лес\n",
    "forest_result = pd.DataFrame(columns = ['estim', 'depth', 'accuracy_train', 'accuracy_valid'])\n",
    "i= 0\n",
    "for estim in range(5, 51, 5):\n",
    "    for depth in range(2, 11, 2):\n",
    "        model_forest = RandomForestClassifier(n_estimators=estim, max_depth=depth, random_state=12345)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        predictions_forest_train = model_forest.predict(features_train)\n",
    "        predictions_forest_valid = model_forest.predict(features_valid)\n",
    "        accuracy_forest_train = accuracy_score(target_train, predictions_forest_train)\n",
    "        accuracy_forest_valid = accuracy_score(target_valid, predictions_forest_valid)\n",
    "        forest_result.loc[i, 'estim'] = estim\n",
    "        forest_result.loc[i, 'depth'] = depth\n",
    "        forest_result.loc[i, 'accuracy_train'] = accuracy_forest_train\n",
    "        forest_result.loc[i, 'accuracy_valid'] = accuracy_forest_valid\n",
    "        i +=1\n",
    "    \n",
    "forest_result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество логистической регрессии на обучающей выборке: 0.7479253112033195\n",
      "Качество логистической регрессии на валидационной выборке: 0.7542768273716952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tehnodent\\DS\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#исследуем логистическую регрессию\n",
    "model_log = LogisticRegression(random_state=12345)\n",
    "model_log.fit(features_train, target_train)\n",
    "predictions_log_train = model_log.predict(features_train)\n",
    "predictions_log_valid = model_log.predict(features_valid)\n",
    "accuracy_log_train = accuracy_score(target_train, predictions_log_train)\n",
    "accuracy_log_valid = accuracy_score(target_valid, predictions_log_valid)\n",
    "print('Качество логистической регрессии на обучающей выборке:', accuracy_log_train )\n",
    "print('Качество логистической регрессии на валидационной выборке:', accuracy_log_valid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное значение качества модели \"Дерево\" на валидационной выборке: 0.7853810264385692\n",
      "Максимальное значение качества модели \"Лес\" на валидационной выборке: 0.8087091757387247\n",
      "Значение качества логистической модели на валидационной выборке: 0.7542768273716952\n"
     ]
    }
   ],
   "source": [
    "#выбираем лучшую модель\n",
    "print('Максимальное значение качества модели \"Дерево\" на валидационной выборке:', tree_result['accuracy_valid'].max())\n",
    "print('Максимальное значение качества модели \"Лес\" на валидационной выборке:', forest_result['accuracy_valid'].max())\n",
    "print('Значение качества логистической модели на валидационной выборке:', accuracy_log_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выбираем лес, т.к. его качество выше остальных. Вторым идёт дерево, и потом уже - логистическая регрессия. Однако, дерево более склонно к переобучению, чем регрессия, так как размах между качеством обучающей модели и качеством валидационной у неё больше всего."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([38], dtype='int64')\n",
      "Качество модели на тестовой выборке: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "#находим индекс строки с максимальным значением, чтобы задать такие же гиперпараметры\n",
    "max_accuracy = forest_result['accuracy_valid'].max()\n",
    "print(forest_result.query('accuracy_valid == @max_accuracy').index)\n",
    "\n",
    "#считаем качество модели на тестовой выборке\n",
    "model = RandomForestClassifier(n_estimators=40, max_depth=8, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predictions= model.predict(features_test)\n",
    "accuracy = accuracy_score(target_test, predictions)\n",
    "print('Качество модели на тестовой выборке:',accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество модели соответствует требованиям: практически в 80% случаев модель предскажет правильный тариф."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество модели на тестовой выборке: 0.3157076205287714\n"
     ]
    }
   ],
   "source": [
    "#попробуем сделать 10 случайных моделей, сравним качество\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sanity_check = RandomForestClassifier(n_estimators=40, max_depth=8, random_state=12345)\n",
    "sanity_check.fit(features_train, target_train)\n",
    "predictions_check= np.ones(target_test.shape)\n",
    "accuracy_check = accuracy_score(target_test, predictions_check)\n",
    "print('Качество модели на тестовой выборке:',accuracy_check)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель адекватна, так как ее качество существенно лучше качества baseline модели"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
